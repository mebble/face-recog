{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "def get_cropped(img, final_size):\n",
    "    '''\n",
    "    Resize the image through its smallest dimension,\n",
    "    then crop out the center and return as np array.\n",
    "    final_size must be <= the min of image dimension\n",
    "    '''\n",
    "    size = img.size\n",
    "    ratio = float(final_size) / min(size)\n",
    "    new_image_size = tuple([int(x*ratio) for x in size])\n",
    "    img = img.resize(new_image_size, Image.ANTIALIAS)\n",
    "    width, height = img.size\n",
    "    w_mid, h_mid = width // 2, height // 2\n",
    "    img = np.array(img)\n",
    "    img = img[(h_mid-final_size//2):(h_mid+final_size//2), (w_mid-final_size//2):(w_mid+final_size//2)]\n",
    "    \n",
    "    if img.shape == (final_size, final_size, 3):\n",
    "        return img[:, :, 0]  # take only one channel of the image\n",
    "    else:\n",
    "        print('Error: Image size = {}'.format(size))\n",
    "\n",
    "def load_images_from_dir(dirpath):\n",
    "    images = []\n",
    "    for filename in os.listdir(dirpath):\n",
    "        try:\n",
    "            img = Image.open(os.path.join(dirpath,filename))\n",
    "            images.append(img)\n",
    "        except:\n",
    "            pass\n",
    "    return images\n",
    "\n",
    "def load_data(dirpath):\n",
    "    '''Dont end the dirpath in a slash'''\n",
    "    imgs = load_images_from_dir(dirpath)\n",
    "    imgs = [get_cropped(img, IMG_SIZE) for img in imgs]\n",
    "    imgs = [img for img in imgs if img is not None]\n",
    "    labels = [int(os.path.basename(dirpath)) for _ in imgs]\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    #convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #load OpenCV face detector, using LBP which is fast\n",
    "    #there is also a more accurate but slow Haar classifier\n",
    "    face_cascade = cv2.CascadeClassifier('opencv-files/lbpcascade_frontalface.xml')\n",
    "\n",
    "    #detect multiscale (some images may be closer to camera than others) images\n",
    "    #result is a list of faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5);\n",
    "    \n",
    "    #if no faces are detected then return original img\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    #under the assumption that there will be only one face,\n",
    "    #extract the face area\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    #return only the face part of the image\n",
    "    return gray[y:y+w, x:x+h], faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Image size = (412, 549)\n",
      "Error: Image size = (499, 664)\n"
     ]
    }
   ],
   "source": [
    "subjects = [\"\", \"One\", \"Two\"]\n",
    "\n",
    "# Dont end the dirpath in a slash\n",
    "dirOne = 'gallaghar-cropped/8'\n",
    "dirTwo = 'gallaghar-cropped/9'\n",
    "\n",
    "faces1, labels1 = load_data(dirOne)  # images of subject One\n",
    "faces2, labels2 = load_data(dirTwo)  # images of subject Two\n",
    "\n",
    "faces = faces1 + faces2\n",
    "labels = labels1 + labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "# face_recognizer = cv2.face.FisherFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to draw rectangle on image \n",
    "#according to given (x, y) coordinates and \n",
    "#given width and heigh\n",
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "#function to draw text on give image starting from\n",
    "#passed (x, y) coordinates. \n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function recognizes the person in image passed\n",
    "#and draws a rectangle around detected face with name of the \n",
    "#subject\n",
    "def predict(test_img):\n",
    "    #make a copy of the image as we don't want to chang original image\n",
    "    img = test_img.copy()\n",
    "    #detect face from the image\n",
    "    face, rect = detect_face(img)\n",
    "\n",
    "    #predict the image using our face recognizer \n",
    "    label= face_recognizer.predict(face)\n",
    "    #get name of respective label returned by face recognizer\n",
    "    label_text = subjects[label]\n",
    "    \n",
    "    #draw a rectangle around face detected\n",
    "    draw_rectangle(img, rect)\n",
    "    #draw name of predicted person\n",
    "    draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting images...\")\n",
    "\n",
    "#load test images\n",
    "test_img1 = cv2.imread('{}/794.jpg'.format(dirTwo))\n",
    "test_img2 = cv2.imread('{}/678.jpg'.format(dirOne))\n",
    "\n",
    "#perform a prediction\n",
    "predicted_img1 = predict(test_img1)\n",
    "predicted_img2 = predict(test_img2)\n",
    "print(\"Prediction complete\")\n",
    "\n",
    "#display both images\n",
    "cv2.imshow(subjects[1], predicted_img1)\n",
    "cv2.imshow(subjects[2], predicted_img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
